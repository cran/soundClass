<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>example</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>


<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">example</h1>



<p>To demonstrate the package functionality we are going to train a
simple bat detector and test it on new sampling recordings. We start by
loading the soundClass package:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(soundClass)</span></code></pre></div>
<p>Please note that before using soundClass for the first time it is
necessary to have tensorflow and keras backend installed. This can be
achieved by running the function install_keras(). If prompted to install
‘miniconda’ type ‘Y’ to install it:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>keras<span class="sc">::</span><span class="fu">install_keras</span>() <span class="co"># only needed before first use of soundClass</span></span></code></pre></div>
<p>To run the example, external data must be downloaded and
uncompressed. We first start by creating a new folder to store the data.
We define that folder as the working directory for convenience:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>folder_path <span class="ot">&lt;-</span> <span class="st">&quot;~/data_example/&quot;</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dir.create</span>(folder_path)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">setwd</span>(folder_path)</span></code></pre></div>
<p>The data should now be manually downloaded to the new folder and
unziped: <a href="https://drive.google.com/uc?export=download&amp;id=11GmnMC54-SnHwahAymRIIFJ9evsQ3w6P" class="uri">https://drive.google.com/uc?export=download&amp;id=11GmnMC54-SnHwahAymRIIFJ9evsQ3w6P</a>
The downloaded data includes an already created annotations database, as
well as the necessary recordings for training and validation. The
database was created with the app_label(), as there is no way of
creating it by scripting, and contains the annotations of relevant and
non-relevant sound events in the supplied training recordings. After
unzip, the data_example folder should have the following structure:</p>
<pre><code>data_example
  |     db_bat_calls.sqlite3
  |
  └──── training_recordings
  |
  └──── validation_recordings</code></pre>
<p>A custom blank model is provided with the package but should be
copied to an external folder for easy access, specially for using the
app_model():</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>model_path <span class="ot">&lt;-</span> <span class="fu">system.file</span>(<span class="st">&quot;model_architectures&quot;</span>, <span class="st">&quot;model_vgg_sequential.R&quot;</span>, <span class="at">package=</span><span class="st">&quot;soundClass&quot;</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">file.copy</span>(model_path, <span class="st">&quot;~/data_example/&quot;</span>) <span class="co"># Copy custom blank model to the folder &#39;data_example&#39;</span></span></code></pre></div>
<p>If an annotations database already exists, there are two ways of
using the package to fit or to run a fitted model: 1) by using the
app_model() or 2) by scripting as shown in this example. To create the
train data, spectrogram images with a pre-defined size and centered at
the annotations of the recordings are calculated with the function
spectro_calls(). Several parameters regarding the computation of the
spectrograms must be set to run this function. Some parameters refer to
image resolution and are generalist but the following three are directly
related to the type of events being classified: “spec_size”,
“window_length” and “freq_range”. These parameters refer to the total
size of the spectrogram, the size of the moving window and the
frequencies range in analysis and should be chosen to cover: the maximum
event length, the rate of change (quickly changing events should use
shorter windows) and the typical frequencies range of the events being
classified. As European insectivorous bats (excluding Rhinolophus genus)
are the target, we chose appropriate settings based on bibliography:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># To use the app instead of scripting:</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co"># app_model()</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>train_calls <span class="ot">&lt;-</span> <span class="fu">spectro_calls</span>(</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">files_path =</span> <span class="st">&quot;~/data_example/training_recordings/&quot;</span>,</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">db_path =</span> <span class="st">&quot;~/data_example/db_bat_calls.sqlite3&quot;</span>,</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">spec_size =</span> <span class="dv">20</span>,</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">window_length =</span> <span class="fl">0.5</span>, </span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">frequency_resolution =</span> <span class="dv">1</span>,</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">overlap =</span>  <span class="fl">0.5</span>,</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">dynamic_range =</span> <span class="dv">120</span>,</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">freq_range =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">80</span>),</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">tx =</span> <span class="st">&quot;auto&quot;</span>,</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">1002</span>)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co"># save the object to disk</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="fu">save</span>(train_calls, <span class="at">file =</span> <span class="st">&quot;train_calls.RDATA&quot;</span>)</span></code></pre></div>
<p>To run a a fitted model later, some information regarding the
parameters used for creating the training spectrograms will be needed.
These data can be obtained from the train_calls object:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>metadata <span class="ot">&lt;-</span> <span class="fu">train_metadata</span>(train_calls)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co"># save the object to disk</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="fu">save</span>(metadata, <span class="at">file =</span> <span class="st">&quot;metadata.RDATA&quot;</span>)</span></code></pre></div>
<p>Once the data has been prepared, a blank model must be loaded into R
and compiled. A pre-defined model is supplied with the package. Two
variables must be defined in the global environment before loading the
model: the input shape (input_shape) with the format “c(number of rows,
number of columns, number of channels)” and the number of classes
(num_classes). These values can be found in the metadata object created
with train_metada(). Please note that the number of channels is always
1, as we are working with grayscale images:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>input_shape <span class="ot">&lt;-</span> <span class="fu">c</span>(metadata<span class="sc">$</span>parameters<span class="sc">$</span>img_rows, metadata<span class="sc">$</span>parameters<span class="sc">$</span>img_cols, <span class="dv">1</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>num_classes <span class="ot">&lt;-</span> metadata<span class="sc">$</span>parameters<span class="sc">$</span>num_classes</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>model_path <span class="ot">&lt;-</span> <span class="fu">system.file</span>(<span class="st">&quot;model_architectures&quot;</span>, <span class="st">&quot;model_vgg_sequential.R&quot;</span>, <span class="at">package=</span><span class="st">&quot;soundClass&quot;</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(model_path, <span class="at">local=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<p>With the training data prepared and the blank model loaded, the
parameters for compiling and fitting the model must be set. Please note
that as we are using classification models, both parameters “loss” and
“metrics” should always be set as they are in this example. The other
parameters can be tuned as desired. For further information about the
parameters in the optimizer please refer to Keras documentation: <a href="https://keras.io/api/" class="uri">https://keras.io/api/</a>.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a> model <span class="sc">%&gt;%</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">compile</span>(</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>   <span class="at">optimizer =</span> <span class="fu">optimizer_sgd</span>(</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">learning_rate =</span> <span class="fl">0.01</span>,</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>                <span class="at">momentum =</span> <span class="fl">0.9</span>,</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>                <span class="at">nesterov =</span> <span class="cn">TRUE</span>),</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>   <span class="at">loss =</span> <span class="st">&#39;categorical_crossentropy&#39;</span>,</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>   <span class="at">metrics =</span> <span class="st">&#39;accuracy&#39;</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<p>The model is now ready to be fitted. Three callbacks (objects that
can perform actions at various stages of training) are defined: 1) early
stopping, 2) model checkpoint and 3) CSV logger. These objects permit
to, respectively: 1) stop the fitting process if there is no improvement
in the validation dataset accuracy for a defined number of epochs, 2)
save the partially fitted model to disk (the workfolder in this example)
after each iteration and keep only the best model after training for
further use and 3) save to disk the log (the workfolder in this example)
of the training process. For further information about the callbacks
available and their usage please refer to Keras documentation (<a href="https://keras.io/api/" class="uri">https://keras.io/api/</a>). To
fit the model the function keras::fit() is used:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a> model <span class="sc">%&gt;%</span> keras<span class="sc">::</span><span class="fu">fit</span>(train_calls<span class="sc">$</span>data_x,</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>        train_calls<span class="sc">$</span>data_y,</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">batch_size =</span> <span class="dv">512</span>,</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">epochs =</span> <span class="dv">20</span>,</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>        <span class="at">callbacks =</span> <span class="fu">list</span>(</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>         <span class="fu">callback_early_stopping</span>(<span class="at">patience =</span> <span class="dv">4</span>, <span class="at">monitor =</span> <span class="st">&#39;val_accuracy&#39;</span>),</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>         <span class="fu">callback_model_checkpoint</span>(<span class="st">&quot;./fitted_model.hdf5&quot;</span>,</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>                      <span class="at">monitor =</span> <span class="st">&quot;val_accuracy&quot;</span>, <span class="at">save_best_only =</span> T),</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>         <span class="fu">callback_csv_logger</span>(<span class="st">&quot;./fitted_model_log.csv&quot;</span>)),</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>        <span class="at">shuffle =</span> <span class="cn">TRUE</span>,</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>        <span class="at">validation_split =</span> <span class="fl">0.3</span>,</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>        <span class="at">verbose =</span> <span class="dv">1</span>)</span></code></pre></div>
<p>The fitted model and an additional log file are saved to disk in the
working folder for further use in the classification of novel
recordings. To validate our model, we use recordings not used to
calibrate the model. We use recordings with the same species used for
training but also new bat species to evaluate the model transferability.
The classification is applied to the recordings with function auto_id()
and the results are saved to a folder created in the same folder where
the recordings are, in this cased named “output”:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">auto_id</span>(<span class="at">model_path =</span> <span class="st">&quot;./fitted_model.hdf5&quot;</span>,</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">metadata =</span> metadata,</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">file_path =</span> <span class="st">&quot;~/data_example/validation_recordings/&quot;</span>,</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">out_file =</span> <span class="st">&quot;id_results&quot;</span>,</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>        <span class="at">out_dir =</span> <span class="st">&quot;~/data_example/validation_recordings/output/&quot;</span>,</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>        <span class="at">save_png =</span> <span class="cn">TRUE</span>,          </span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>        <span class="at">win_size =</span> <span class="dv">40</span>,</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">remove_noise =</span> <span class="cn">TRUE</span>,</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>        <span class="at">plot2console =</span> <span class="cn">FALSE</span>,</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>        <span class="at">recursive =</span> <span class="cn">FALSE</span>,</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>        <span class="at">tx =</span> <span class="st">&quot;auto&quot;</span>)</span></code></pre></div>
<p>The classification process outputs a database in the sqlite3 format
with all the relevant events detected and the respective probability to
belong to a given class. Additionally a file in the CSV format is saved
to disk, containing summary statistics per recording, i.e. the class
with most events detected in each particular recording and the average
frequency of maximum energy of the events detected, for reporting and
manual review. If desired, one spectrogram per recording with the
temporal position of the events detected may also be obtained.</p>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
